%
% File eacl2017.tex
%
%% Based on the style files for ACL-2016
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage{acl2017}
\usepackage{times}
\usepackage{multirow}
\usepackage{url}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{color}
\usepackage{booktabs}
\usepackage{amsmath}

\aclfinalcopy % Uncomment this line for the final submission
%\def\eaclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Vietnamese Named Entity Recognition System \\ in underthesea v1.1.8}

\include{notation}

\author{
Vu Anh\\
underthesea\\
Hanoi, Vietnam\\
anhv.ict91@gmail.com
}
\date{}

\begin{document}
\maketitle
\begin{abstract}
In this report, we describe our named entity recognition system for Vietnamese, which is integrated in underthesea version 1.1.8.
Our system is open-source and available at \url{https://github.com/undertheseanlp/ner}

\end{abstract}

\section{Introduction}

Named entity recognition (NER) is a fundamental task in natural language processing and information extraction.
It involves identifying noun phrases and classifying each of them into a predefined class.
In 1995, the 6th Message Understanding Conference (MUC) started evaluating NER systems for English, and in subsequent shared tasks of CoNLL 2002 and CoNLL 2003 conferences, language independent NER systems were evaluated.
In the evaluation tasks, four named entity types were considered, including names of persons, organizations, locations, and names of miscellaneous entities that do not belong to these three types.

In Vietnamese, there have been some shared tasks for evaluating NER systems, such as VLSP 2016, VLSP 2018.

Previously published systems for Vietnamese named entity recognition used machine learning methods such as Condition Random Field ~\cite{DBLP:journals/corr/abs-1803-08463}, MEMM ~\cite{DBLP:journals/corr/Le-Hong16}, BiLSTM-CNN-CRF ~\cite{DBLP:journals/corr/abs-1708-07241}, dynamic feature induction ~\cite{DBLP:journals/corr/abs-1801-01331}.

\section{System Description}

In this section we describe machine-learning approach thhave adapted to the Vietnamese Named Entity Recognition task, Conditional Random Fields.

\subsection{Conditional Random Fields}

Conditional Random Fields are a discriminative model, used for predicting sequences.
They use contextual information from previous labels, thus increasing the amount of information the model has to make a good prediction.

A linear-chain CRF with parameters $\lambda = \{ \lambda_1, ... , \lambda_n \}$ defines a conditional probability for a state (or label) sequence $Y = y_1,..., y_T$ given an input sequence $X = x_1,..., x_T$ to be

$$P_{\lambda} (Y|X) = \frac{1}{Z_{\tx}} exp \left{ \sum_{l=1}^{T} \right \sum_k \lambda_k f_k \left( y_{t-1}, y_t, X, t\right)}$$

where

\begin{itemize}
  \item $f_k(y_{t-1}, y_t, X, t)$ is a feature function which if often binary-valued
  \item $\lambda_{k}$ is a learned weight associated with feature $f$
\end{itemize}

$Z_X$ is the normalization factor over all state sequences

$$Z_X = \sum_y exp \{ \sum_{t=1}^{T} \sum_{k} \lambda_k f_k \left( y_{t-1}, y_t, X, t \right) \}$$

The most probable label sequence for an input $X$, can be efficiently determined using the Viterbi algorithm

$$y^{*} = \underset{y}{argmax} P_{\lambda} \left( Y | X \right)$$

\section{Evaluation}

\subsection{Data sets}

\noindent \textbf{VLSP 2016:} The data set given by the VLSP 2016 includes 267 text documents, which have already segmented.
They contain 16858 sentences with more than 15000 named entities in which LOC and PER are two popular entity types (90\%).
The summarization of the given data set is described in Table I

\begin{table}
  \centering
  \begin{tabular}{ccccc}
    \toprule
     & Count & Percent \\
    \midrule
    LOC  & 6245 & 41\% \\
    MISC  & 282 & 2\% \\
    ORG & 1213 & 8\% \\
    PER & 7480 & 49\% \\
    \bottomrule
  \end{tabular}

  \label{tab:vlsp2016}
  \caption{\small The statistic of VLSP 2016 dataset}
\end{table}

\noindent \textbf{VLSP 2018}

% TODO To be updated

\subsection{Evaluation Measures}

We used Precision, Recall, F1 score as evaluation measures.

$$F_1 = \frac{2*P*R}{P + R}$$

where P (Precision), and R (Recall) are determined as follows:

$$P = \frac{{NE}_{true}}{NE_{sys}}$$

$$R = \frac{{NE}_{true}}{NE_{ref}}$$

where

$NE_{true}$: The number of NEs in gold data

$NE_{sys}$: The number of NEs in recognizing system

$NE_{true}$: The number of NEs which is correctly recognized by the system

\subsection{Results}

% TODO To be updated

\section{Conclusion}

We have introduced our approach and its experimental result in named entity recognition for Vietnamese text.

% TODO To be updated

\bibliography{technique_report}
\bibliographystyle{acl_natbib}

\end{document}
